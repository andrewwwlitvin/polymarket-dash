name: Build and publish dashboards

on:
  schedule:
    - cron: "0 */6 * * *"   # every 6 hours (UTC)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 25      # optional: cap the entire job
    concurrency:
      group: deploy-${{ github.ref }}
      cancel-in-progress: false
      
    env:
      TZ: Europe/Lisbon

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          
      - name: Fetch latest markets (fast top-k)
        timeout-minutes: 15
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          set -euo pipefail

          echo "GITHUB_WORKSPACE=$GITHUB_WORKSPACE"
          WORKDIR="$GITHUB_WORKSPACE"
          DATA_DIR="$WORKDIR/data"
          mkdir -p "$DATA_DIR"

          # Reuse CSV if <5h old
          recent=$(find "$DATA_DIR" -maxdepth 1 -type f -name 'polymarket_enriched_fast_*.csv' -mmin -300 | sort | tail -n1 || true)
          if [ -n "${recent:-}" ]; then
            echo "Using recent CSV: $recent"
            echo "LATEST_CSV=$recent" >> "$GITHUB_ENV"
          else
            echo "No recent CSV; fetching a new oneâ€¦"
            python -u "$WORKDIR/scripts/polymarket_enriched_fast.py" \
              --topk 120 \
              --concurrency 8 \
              --fast

            echo "Search for new CSVs (top-level and scripts/):"
            find "$WORKDIR" -maxdepth 2 -type f -name 'polymarket_enriched_fast_*.csv' -printf '%TY-%Tm-%Td %TH:%TM %p\n' | sort || true

            latest=$(find "$WORKDIR" -maxdepth 2 -type f -name 'polymarket_enriched_fast_*.csv' | sort | tail -n1 || true)
            if [ -z "${latest:-}" ]; then
              echo "ERROR: Fetcher did not produce a CSV named polymarket_enriched_fast_*.csv"
              exit 1
            fi

            base=$(basename "$latest")
            mv "$latest" "$DATA_DIR/$base"
            echo "Fetched CSV: $DATA_DIR/$base"
            echo "LATEST_CSV=$DATA_DIR/$base" >> "$GITHUB_ENV"
          fi

          echo "List data dir:"
          ls -lAh "$DATA_DIR" || true
          
      - name: Generate site (use explicit CSV)
        run: |
          set -euo pipefail
          echo "GITHUB_WORKSPACE=$GITHUB_WORKSPACE"
          echo "LATEST_CSV env: ${LATEST_CSV:-<empty>}"

          if [ -z "${LATEST_CSV:-}" ]; then
            echo "ERROR: LATEST_CSV is not set; aborting to avoid publishing sample data."
            exit 1
          fi
          if [ ! -f "$LATEST_CSV" ]; then
            echo "ERROR: LATEST_CSV path does not exist: $LATEST_CSV"
            echo "Directory listing of $(dirname "$LATEST_CSV"):"
            ls -lAh "$(dirname "$LATEST_CSV")" || true
            exit 1
          fi

          echo "Building site from: $LATEST_CSV"
          head -n 2 "$LATEST_CSV" | sed 's/^/[csv head] /' || true

          python "$GITHUB_WORKSPACE/scripts/build_site_from_csv.py" "$LATEST_CSV"
          
      - name: Configure Git
        run: |
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Commit and push artifacts
        run: |
          set -e
          git add -A
          if git diff --cached --quiet; then
            echo "Nothing to commit"; exit 0
          fi
          git pull --rebase --autostash origin "$GITHUB_REF_NAME" || true
          if git push origin HEAD:"$GITHUB_REF_NAME"; then
            echo "Push ok"
          else
            echo "Push failed; retrying after rebase"
            git pull --rebase --autostash origin "$GITHUB_REF_NAME" || true
            git push origin HEAD:"$GITHUB_REF_NAME"
          fi
